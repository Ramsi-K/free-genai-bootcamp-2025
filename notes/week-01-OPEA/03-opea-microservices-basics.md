# Basics of Microservices in OPEA

## üìå Index

1. üîπ [What are Microservices?](#1Ô∏è‚É£-what-are-microservices)
2. üçΩÔ∏è [Microservices vs. Monolith: The Restaurant Analogy](#2Ô∏è‚É£-microservices-vs-monolith-the-restaurant-analogy)
3. üöÄ [Simple Scenarios for Understanding OPEA Microservices](#3Ô∏è‚É£-simple-scenarios-for-understanding-opea-microservices)
4. üõ†Ô∏è [Basic Microservices in OPEA](#4Ô∏è‚É£-basic-microservices-in-opea)
5. üîÑ [How Microservices Communicate](#5Ô∏è‚É£-how-microservices-communicate)
6. üé® [Microservices Diagram](#6Ô∏è‚É£-microservices-diagram)
7. üèóÔ∏è [Simple Hands-On Example](#7Ô∏è‚É£-simple-hands-on-example)
8. ü§Ø [Common Misconceptions About Microservices](#8Ô∏è‚É£-common-misconceptions-about-microservices)
9. üìö [Glossary of Microservices Terms](#glossary-of-microservices-terms)

---

## **1Ô∏è‚É£ What are Microservices?**

Think of microservices like a team of specialists working together, each with their own expertise:

‚úÖ Instead of one application doing everything (**a monolith**), microservices **split responsibilities**.  
‚úÖ Each service **focuses on one job** and does it well.  
‚úÖ Services **talk to each other** over a network.  
‚úÖ If one service fails, **the others can keep running**.

---

## **2Ô∏è‚É£ Microservices vs. Monolith: The Restaurant Analogy**

### üçΩÔ∏è **Monolithic Application (One Chef Restaurant)**

- **One chef** does everything‚Äîtakes orders, cooks all dishes, serves food, and handles payments.
- **Pros**: Simple to coordinate, no communication issues.
- **Cons**: If the chef is sick, the entire restaurant shuts down.

### üçΩÔ∏è **Microservices Architecture (Specialized Kitchen Staff)**

- **Host takes orders**, different chefs cook different dishes, **servers deliver food**, and **cashier handles payment**.
- **Pros**: More efficient, staff can specialize, one absent worker doesn‚Äôt shut down the whole restaurant.
- **Cons**: Requires coordination, communication overhead.

---

## **3Ô∏è‚É£ Simple Scenarios for Understanding OPEA Microservices**

### **Scenario 1: Processing a User Query in OPEA**

1. **User asks a chatbot a question**.
2. **Gateway Service** authenticates the user.
3. **Orchestration Service** determines which AI model to use.
4. **Data Processing Service** cleans and formats the input.
5. **AI Inference Service** runs the query through the model.
6. **Storage Service** retrieves relevant data to improve the response.
7. **Gateway Service** sends the final response back to the user.

### **Scenario 2: Scaling During High Traffic**

1. **Monday morning**: Many users start using OPEA simultaneously.
2. **Monitoring Service** detects increased CPU usage on AI Inference Service.
3. **Kubernetes HPA** automatically creates more AI Inference Service pods.
4. **Load Balancer** distributes requests evenly.
5. **After peak hours**: System scales down to save resources.

---

## **4Ô∏è‚É£ Basic Microservices in OPEA**

- **üõ†Ô∏è Gateway Service** ‚Üí Routes API requests and ensures authentication.
- **üìú Authentication Service** ‚Üí Manages user login and API keys.
- **üß† AI Inference Service** ‚Üí Runs AI models to generate responses.
- **üíæ Storage Service** ‚Üí Stores and retrieves structured & unstructured data.
- **‚öôÔ∏è Orchestration Service** ‚Üí Manages workflows and service coordination.
- **üìä Monitoring Service** ‚Üí Tracks service health, logs, and system performance.

---

## **5Ô∏è‚É£ How Microservices Communicate**

üîπ **REST APIs** ‚Äì Simple, stateless HTTP requests between services.  
üîπ **Message Queues (Kafka, RabbitMQ)** ‚Äì Event-driven processing.  
üîπ **Service Discovery** ‚Äì Services find each other dynamically inside Kubernetes.

```mermaid
flowchart LR
subgraph "Request-Response Pattern"
A[Service A] -->|HTTP/gRPC Request| B[Service B]
B -->|Response| A
end

    subgraph "Event-Driven Pattern"
        C[Service C] -->|Publish Event| MQ[(Message Queue)]
        MQ -->|Consume Event| D[Service D]
        MQ -->|Consume Event| E[Service E]
    end

    subgraph "Service Mesh Pattern"
        F[Service F] -->|Request| SM{Service Mesh Proxy}
        SM -->|Routed Request| G[Service G]
        G -->|Response| SM
        SM -->|Routed Response| F
    end

    classDef service fill:#bfb,stroke:#333,stroke-width:2px
    classDef queue fill:#bbf,stroke:#333,stroke-width:2px
    classDef mesh fill:#fbf,stroke:#333,stroke-width:2px

    class A,B,C,D,E,F,G service
    class MQ queue
    class SM mesh
```

---

## **6Ô∏è‚É£ Microservices Diagram**

```mermaid
flowchart TB
    Client[Client Applications] --> Gateway[API Gateway Service]

    subgraph "OPEA Microservices"
        Gateway --> Auth[Authentication Service]
        Gateway --> Inference[AI Inference Service]
        Gateway --> Storage[Storage & Retrieval Service]

        Auth --> Monitoring[Monitoring Service]
        Inference --> Monitoring
        Storage --> Monitoring

        Inference --> Storage
        Inference --> Orchestration[Orchestration Service]
        Orchestration --> DataProc[Data Processing Service]
        DataProc --> Storage
    end

    classDef gateway fill:#f96,stroke:#333,stroke-width:2px
    classDef auth fill:#bbf,stroke:#333,stroke-width:2px
    classDef inference fill:#bfb,stroke:#333,stroke-width:2px
    classDef storage fill:#fbb,stroke:#333,stroke-width:2px
    classDef monitoring fill:#fbf,stroke:#333,stroke-width:2px
    classDef orchestration fill:#bff,stroke:#333,stroke-width:2px
    classDef dataproc fill:#ffb,stroke:#333,stroke-width:2px

    class Gateway gateway
    class Auth auth
    class Inference inference
    class Storage storage
    class Monitoring monitoring
    class Orchestration orchestration
    class DataProc dataproc
```

## **7Ô∏è‚É£ Simple Hands-On Example**

A basic **FastAPI-based microservice** in Python:

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/ping")
def ping():
    return {"message": "Service is running"}
```

üöÄ **Run the service**:

```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```

---

## **8Ô∏è‚É£ Common Misconceptions About Microservices**

#### **1: "Microservices are always better than monoliths"**

**Reality**: Microservices add complexity that may not be justified for smaller applications or teams. OPEA uses microservices because of its enterprise scale and complex AI requirements.

#### **2: "Each microservice should be as small as possible"**

**Reality**: Services should be sized by business capability, not code volume. Breaking things down too much creates unnecessary communication overhead.

#### **3: "Microservices eliminate all dependencies"**

**Reality**: They change the nature of dependencies from in-code to network-based. Services still rely on each other, just in different ways.

#### **4: "Microservices can scale infinitely"**

**Reality**: While microservices allow for targeted scaling, constraints still exist‚Äîlike database bottlenecks, network latency, and resource limits.

#### **5: "Microservices guarantee better performance"**

**Reality**: Microservices can introduce latency due to inter-service communication. Without proper optimizations (caching, batching, etc.), they can be **slower** than a well-optimized monolith.

#### **6: "Microservices are just about splitting code"**

**Reality**: Microservices architecture is about **independent deployment and scaling**, not just breaking code into small pieces.

---

## **Glossary of Microservices Terms**

| Term              | Definition                                                             |
| ----------------- | ---------------------------------------------------------------------- |
| **API Gateway**   | The entry point that routes requests to appropriate microservices      |
| **Container**     | A lightweight package that includes everything needed to run a service |
| **Docker**        | Platform used to package applications into containers                  |
| **Kubernetes**    | System for managing and scaling containerized applications             |
| **Load Balancer** | Distributes incoming network traffic across multiple service instances |

---

_Made by Ramsi K. ‚Äì Part of the GenAI Bootcamp 2025 repository._
