# Week 00: GenAI Essentials  

## Overview  

This week covers the **fundamentals of AI and Generative AI**, focusing on:  

- The basics of **AI, ML, and DL**  
- Understanding **Generative AI vs. Traditional AI**  
- The **transformer architecture and tokenization**  
- How **LLMs are trained, fine-tuned, and deployed**  
- Hands-on **labs for prompt engineering and model evaluation**  

---

## Notes for This Week  

| **Topic** | **Description** |
|-----------|----------------|
| [**Intro to AI & Generative AI**](intro.md) | Covers AI, ML, DL, Generative AI, and LLMs. |
| [**AI vs. Generative AI**](02-genai-vs-traditional-ai.md) | Differences, applications, and impact. |
| [**LLM Basics**](03-llm-basics.md) | Foundational models, embeddings, vector spaces. |
| [**Transformer Architecture**](04-transformers.md) | Breakdown of the transformer model, attention mechanisms, and tokenization. |
| [**Tokenization**](05-tokenization.md) | Word, subword, and character-based tokenization methods. |
| [**Embeddings**](06-embeddings.md) | Word embeddings, sentence embeddings, and cosine similarity. |
| [**BERT and Variants**](07-bert-and-variants.md) | BERT architecture, RoBERTa, ALBERT, DistilBERT, and applications. |
| [**Fine-Tuning LLMs**](08-fine-tuning-llms.md) | Techniques like supervised fine-tuning, LoRA, RLHF. |
| [**Data & Machine Learning**](09-data-and-ml.md) | Data mining, wrangling, labeling, and ML pipelines. |
| [**Prompt Engineering**](10-prompt-engineering.md) | Strategies like Few-shot, Chain-of-Thought, ReAct. |
| [**LLM Development Tools**](11-llm-dev-tools.md) | Tools like Hugging Face, LangChain, LlamaIndex. |
| [**Model as a Service**](12-model-as-a-service.md) | Overview of Amazon Bedrock, Azure AI, Google Vertex AI. |
| [**GenAI Security**](13-genai-security.md) | AI security risks like prompt injection, adversarial attacks. |
| [**Context Caching**](14-context-caching.md) | Optimizing model efficiency with caching techniques. |
| [**GenAI Hardware**](15-hardware-for-genai.md) | GPUs, TPUs, Intel Gaudi, cloud infrastructure. |
| [**Evaluations & Metrics**](16-evaluations-and-metrics.md) | Perplexity, BLEU scores, token efficiency benchmarks. |
| [**Serving Models**](17-serving-models.md) | KServe, Ray, TensorRT LLM, and real-time deployment. |
| [**Enterprise & Production AI**](18-production-enterprise.md) | Scaling AI models, multi-cloud deployment, cost optimization. |

---

## Key Learnings  

- **AI vs. Generative AI**: Key differences in functionality and output.  
- **How transformers revolutionized NLP** through self-attention.  
- **Optimizing AI efficiency** with caching, quantization, and better architectures.  
- **Security risks in AI** and how to mitigate them.  

---

This covers the **foundations** of the bootcamp.
