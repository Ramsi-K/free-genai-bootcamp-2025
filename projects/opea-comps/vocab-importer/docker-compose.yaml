version: '5'

services:
  vllm-server:
    image: opea/vllm:latest
    container_name: vllm-server
    ports:
      - '8008:80'
    volumes:
      - './data:/data'
    shm_size: 1g
    environment:
      - LLM_MODEL_ID=deepseek-ai/deepseek-coder-1.3b-instruct
    command: --model deepseek-ai/deepseek-coder-1.3b-instruct --host 0.0.0.0 --port 80
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:80/health']
      interval: 10s
      timeout: 5s
      retries: 5

  korean-vocab-importer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: korean-vocab-importer
    ports:
      - '8000:8000'
    environment:
      - VLLM_SERVICE_URL=http://vllm-server:80
    depends_on:
      vllm-server:
        condition: service_healthy
    restart: unless-stopped

networks:
  default:
    driver: bridge
